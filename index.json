[{"authors":["admin"],"categories":null,"content":"-- Hello! My name is Animesh Singh Chouhan. I am a final year undergraduate student at Indian Institute of Technology Kharagpur with an interest in backend development, cloud computing, embedded systems and robotics. Seeking an opportunity to apply my experience in a field of interest through research.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"-- Hello! My name is Animesh Singh Chouhan. I am a final year undergraduate student at Indian Institute of Technology Kharagpur with an interest in backend development, cloud computing, embedded systems and robotics. Seeking an opportunity to apply my experience in a field of interest through research.","tags":null,"title":"Animesh Singh","type":"authors"},{"authors":null,"categories":null,"content":"Generate vCard file from CSV\nSetup Cloning the repository: # Clone the repo git clone https://github.com/animesh-chouhan/vcf-creator.git cd vcf-creator # Run the sample csv file python3 -m vcf_creator sample.csv  Installation: To install it right away, type:\npip3 install vcf_creator  Help: python3 -m vcf_creator --help  Running the script: python3 -m vcf_creator \u0026lt;csv-file-name\u0026gt;  CSV File Instructions  The contact CSV file can have the following headers all in smallcase:  name phone organisation email address birthday   The headers can be in any order Make sure that no fields are empty  Usage example Click on the play button to see an example download. \nFor more examples and usage, please refer to the Wiki.\nContributing  Fork the repo (https://github.com/animesh-chouhan/vcf-creator/) Create your feature branch (git checkout -b feature/fooBar) Commit your changes (git commit -am 'Add some fooBar') Push to the branch (git push origin feature/fooBar) Create a new Pull Request  License MIT License copyright (c) 2021 Animesh Singh Chouhan. Please have a look at the license for more details.\n","date":1624924800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624924800,"objectID":"e02196c821e3860a0d65405656fe52ea","permalink":"/project/vcf_creator/","publishdate":"2021-06-29T00:00:00Z","relpermalink":"/project/vcf_creator/","section":"project","summary":"Generate vCard file from CSV","tags":["Web","Youtube"],"title":"VCF Creator","type":"project"},{"authors":null,"categories":null,"content":"List of web compatible simulations and vizualizations:\n Cycloid Particles-1 Particles-2  Contributing  Fork the repo (https://github.com/animesh-chouhan/mathism/) Create your feature branch (git checkout -b feature/fooBar) Commit your changes (git commit -am 'Add some fooBar') Push to the branch (git push origin feature/fooBar) Create a new Pull Request  License MIT License copyright (c) 2020 Animesh Singh Chouhan. Please have a look at the license for more details.\n","date":1579478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579478400,"objectID":"3c09c208cc7228e4c8eef14bfcec984a","permalink":"/project/mathism/","publishdate":"2020-01-20T00:00:00Z","relpermalink":"/project/mathism/","section":"project","summary":"Web compatible simulations and vizualizations.","tags":["Web"],"title":"Mathism","type":"project"},{"authors":null,"categories":null,"content":"A python script to scrape C++ documentation website and generate printable PDF documents. More Info\nSetup Linux: Cloning the repository:\n#clone the repo $git clone https://github.com/animesh-chouhan/cpp-docs-printer.git $cd cpp-docs-printer  Installing the dependencies:\n#install python3-pip $sudo apt-get install python3-pip #requests $sudo pip3 install requests #beautifulsoup4 $sudo pip3 install beautifulsoup4 #weasy-print $sudo apt-get install build-essential python3-dev python3-pip python3-setuptools python3-wheel python3-cffi libcairo2 libpango-1.0-0 libpangocairo-1.0-0 libgdk-pixbuf2.0-0 libffi-dev shared-mime-info $sudo pip3 install WeasyPrint  Running the python script:\n$python3 cplusplus.py http://www.cplusplus.com/reference/cstdio/  Usage example Sample C++ documentation http://www.cplusplus.com/reference/cstdio/:\nSample pdf generated pdf:\nThe generated .html and .pdf files are located in the html and pdf folders respectively.\nFor more examples and usage, please refer to the Wiki.\nBuilt with  requests - Requests is an elegant and simple HTTP library for Python, built for human beings. beautifulsoup - Beautiful Soup is a library that makes it easy to scrape information from web pages. weasyprint - WeasyPrint is a smart solution helping web developers to create PDF documents.  Contributing  Fork the repo (https://github.com/animesh-chouhan/cpp-docs-printer/) Create your feature branch (git checkout -b feature/fooBar) Commit your changes (git commit -am 'Add some fooBar') Push to the branch (git push origin feature/fooBar) Create a new Pull Request  License MIT License copyright (c) 2020 Animesh Singh Chouhan. Please have a look at the license for more details.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"a3fb94554927a9128ea61b53e6552824","permalink":"/project/cpp_docs_printer/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/cpp_docs_printer/","section":"project","summary":"Generates PDF documents from the C++ documentation","tags":["Web","C++"],"title":"C++ Docs Printer","type":"project"},{"authors":null,"categories":null,"content":"Scrapes all the comments from all videos present in a YouTube channel. Can also be used to get the video list from a given YouTube channel.\nSetup Linux:\n#clone the repo git clone https://github.com/animesh-chouhan/yt-comment-scraper.git cd yt-comment-scraper #install python3 sudo apt-get install python3 #install node and npm sudo apt-get install nodejs sudo apt-get install npm #install dependencies npm install express --save npm install puppeteer --save #run the api on localhost node scraper_api.js #testing the python scraper python3 scraper.py ./to_scrape_sample.txt #create a new text file with links to be scraped separated by newlines python3 scraper.py ./your_text_file.txt  Usage example Sample resonse of api hosted on localhost:\nSample comments scraped:\nFor more examples and usage, please refer to the Wiki.\nBuilt With  Puppeteer - Headless browser to overcome pagination ytcomments - Comment API  Contributing  Fork the repo (https://github.com/animesh-chouhan/yt-comment-scraper/) Create your feature branch (git checkout -b feature/fooBar) Commit your changes (git commit -am 'Add some fooBar') Push to the branch (git push origin feature/fooBar) Create a new Pull Request  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"6f40777f93cfde4950a610769c9fe0e1","permalink":"/project/youtube_comment_scraper/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/youtube_comment_scraper/","section":"project","summary":"Scrapes the comments from videos present in a YouTube channel.","tags":["Web","Youtube"],"title":"Youtube Comment Scraper","type":"project"},{"authors":null,"categories":null,"content":"A simple yet powerful script to download and manage local copies of youtube music playlists. It wraps over the youtube-dl downloader and maintains an archive of downloaded songs. It also updates them automatically if a cronjob is configured. More Info\nSetup Cloning the repository: #clone the repo git clone https://github.com/animesh-chouhan/yt-comment-scraper.git cd youtube-playman  Running the script: #run the script directly chmod +x ./youtube-playman.sh ./youtube-playman.sh OR #create a hard link to the local binary folder #this will add the downloader to the path variable ln ./youtube-playman.sh ~/.local/bin/youtube-playman #directly running the script youtube-playman  Installation: To install it right away for all UNIX users (Linux, macOS, etc.), type:\ncurl -L https://github.com/animesh-chouhan/youtube-playman/releases/latest/download/youtube-playman -o ~/.local/bin/youtube-playman chmod a+rx ~/.local/bin/youtube-playman  If you do not have curl, you can alternatively use a recent wget:\nwget https://github.com/animesh-chouhan/youtube-playman/releases/latest/download/youtube-playman -O ~/.local/bin/youtube-playman chmod a+rx ~/.local/bin/youtube-playman  Add Jobs To cron: #creating a cron job that will update the playlists automatically crontab -e  #this will open a editor and add this entry to the file #don't forget the newline after the last entry PATH=\u0026quot;/usr/local/bin:/usr/bin:/bin:/home/\u0026lt;your-username\u0026gt;/.local/bin\u0026quot; @daily printf \u0026quot;update-all\u0026quot; | youtube-playman #OR PATH=\u0026quot;/usr/local/bin:/usr/bin:/bin:/home/\u0026lt;your-username\u0026gt;/.local/bin\u0026quot; @daily printf \u0026quot;update-all\u0026quot; | download \u0026gt; $HOME/Music/cron.log 2\u0026gt;\u0026amp;1;echo `date` \u0026gt;\u0026gt; $HOME/Music/cron.log  For more details refer to ubuntu cron wiki.\nUsage example Click on the play button to see an example download. \nFor more examples and usage, please refer to the Wiki.\nBuilt With  youtube-dl - Command-line program to download videos from YouTube  Contributing  Fork the repo (https://github.com/animesh-chouhan/youtube-playman/) Create your feature branch (git checkout -b feature/fooBar) Commit your changes (git commit -am 'Add some fooBar') Push to the branch (git push origin feature/fooBar) Create a new Pull Request  License MIT License copyright (c) 2020 Animesh Singh Chouhan. Please have a look at the license for more details.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"0d411815c6e0ca49b131ed77a60987f1","permalink":"/project/youtube_playman/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/youtube_playman/","section":"project","summary":"Downloads and updates local copies of YouTube Playlists.","tags":["Web","Youtube"],"title":"Youtube Playman","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1272326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1272326400,"objectID":"68fe1e900090392e3d2a97574964bc5a","permalink":"/project/project3/","publishdate":"2010-04-27T00:00:00Z","relpermalink":"/project/project3/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Coming Soon","type":"project"}]